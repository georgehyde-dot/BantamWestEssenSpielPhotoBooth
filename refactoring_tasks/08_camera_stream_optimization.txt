REFACTORING TASK: Camera Stream Optimization
===========================================

OBJECTIVE:
Optimize the camera preview stream to reduce memory allocations, improve performance, implement buffer pooling, add frame dropping strategies, and establish monitoring for stream health and performance metrics.

CURRENT PROBLEMS:
1. New buffer allocation for every frame at 30fps causes GC pressure
2. Mutex locking on every frame access creates contention
3. No buffer pooling or reuse strategy
4. No frame dropping when system is under load
5. Fixed 33ms interval regardless of actual camera framerate
6. No metrics for stream performance (dropped frames, latency, etc.)
7. Inefficient byte array copying in multiple places
8. No backpressure handling when clients can't keep up
9. Channel capacity is arbitrary (10) without justification
10. No way to adjust quality based on network conditions

FILES TO EXAMINE:
- src/camera.rs (preview_loop function and frame handling)
- src/routes/camera_routes.rs (preview_stream endpoint)
- src/main.rs (spawn_camera function and frame handling)
- Look for these specific patterns:
  - Line in preview_stream: Vec::with_capacity allocations
  - Multiple clone() operations on frame data
  - Mutex locking patterns
  - Fixed interval of 33ms

SPECIFIC PERFORMANCE ISSUES:

1. BUFFER ALLOCATION IN PREVIEW STREAM:
   ```rust
   // Current anti-pattern in camera_routes.rs:
   let mut part = Vec::with_capacity(
       boundary_prefix.len() + header.len() + frame.len() + tail.len()
   );
   // This allocates new memory for EVERY frame!
   ```

2. FRAME CLONING:
   ```rust
   // Multiple clones of frame data:
   let frame_opt = {
       last_frame_arc.lock().unwrap().clone()  // Clone #1
   };
   jpeg_data.clone()  // Clone #2 in camera.rs
   ```

3. FIXED TIMING:
   ```rust
   // Hardcoded 33ms interval regardless of camera capability
   let mut interval = tokio::time::interval(
       tokio::time::Duration::from_millis(33)
   );
   ```

RECOMMENDED OPTIMIZATION STRUCTURE:

1. BUFFER POOL IMPLEMENTATION:
   ```rust
   pub struct FrameBufferPool {
       pools: Vec<Mutex<Vec<Vec<u8>>>>,
       size_classes: Vec<usize>,
       metrics: PoolMetrics,
   }

   impl FrameBufferPool {
       pub fn acquire(&self, size: usize) -> PooledBuffer {
           // Get buffer from appropriate size class
           // Track acquisition metrics
       }

       pub fn release(&self, buffer: PooledBuffer) {
           // Return buffer to pool
           // Clear but keep capacity
       }
   }

   pub struct PooledBuffer {
       data: Vec<u8>,
       pool: Arc<FrameBufferPool>,
       size_class: usize,
   }
   ```

2. LOCK-FREE FRAME EXCHANGE:
   ```rust
   use crossbeam::atomic::AtomicCell;

   pub struct FrameExchange {
       current: Arc<AtomicCell<Option<Arc<Frame>>>>,
       stats: Arc<StreamStats>,
   }

   pub struct Frame {
       data: PooledBuffer,
       timestamp: Instant,
       sequence: u64,
   }
   ```

3. ADAPTIVE STREAMING:
   ```rust
   pub struct AdaptiveStreamController {
       target_fps: f32,
       current_fps: f32,
       quality_levels: Vec<QualityProfile>,
       network_monitor: NetworkMonitor,
   }

   impl AdaptiveStreamController {
       pub fn should_drop_frame(&self) -> bool {
           // Implement frame dropping logic
       }

       pub fn adjust_quality(&mut self) -> QualityProfile {
           // Dynamically adjust based on conditions
       }
   }
   ```

4. STREAMING METRICS:
   ```rust
   pub struct StreamMetrics {
       frames_captured: AtomicU64,
       frames_sent: AtomicU64,
       frames_dropped: AtomicU64,
       bytes_sent: AtomicU64,
       client_count: AtomicU32,
       last_frame_time: Mutex<Instant>,
       average_latency: AtomicU64,
   }
   ```

IMPLEMENTATION GUIDELINES:

1. IMPLEMENT BUFFER POOLING:
   - Create size classes for common frame sizes
   - Pre-allocate buffers at startup
   - Implement acquire/release with RAII pattern
   - Monitor pool efficiency and resize as needed

2. OPTIMIZE FRAME EXCHANGE:
   ```rust
   // Instead of mutex + clone:
   pub async fn get_latest_frame(&self) -> Option<Arc<Frame>> {
       self.current.load()
   }

   // Producer side:
   pub fn update_frame(&self, frame: Frame) {
       let arc_frame = Arc::new(frame);
       let old = self.current.swap(Some(arc_frame));
       // old frame is automatically dropped
   }
   ```

3. IMPLEMENT BACKPRESSURE:
   ```rust
   pub struct StreamClient {
       tx: mpsc::Sender<Arc<Frame>>,
       lag_threshold: Duration,
       last_sent: Instant,
   }

   impl StreamClient {
       pub async fn send_frame(&mut self, frame: Arc<Frame>) -> Result<(), StreamError> {
           // Check if client is lagging
           if self.last_sent.elapsed() > self.lag_threshold {
               return Err(StreamError::ClientLagging);
           }

           // Try send with timeout
           match self.tx.try_send(frame) {
               Ok(()) => {
                   self.last_sent = Instant::now();
                   Ok(())
               }
               Err(TrySendError::Full(_)) => {
                   self.metrics.dropped_frames.inc();
                   Err(StreamError::BufferFull)
               }
               Err(TrySendError::Closed(_)) => {
                   Err(StreamError::ClientDisconnected)
               }
           }
       }
   }
   ```

4. ZERO-COPY STREAMING:
   ```rust
   // Use bytes::Bytes for zero-copy operations
   use bytes::{Bytes, BytesMut};

   pub async fn stream_frame(frame: Arc<Frame>) -> Result<Bytes, Error> {
       let mut buf = BytesMut::with_capacity(calculate_size(&frame));

       // Write directly to buffer without intermediate allocations
       buf.extend_from_slice(&BOUNDARY_PREFIX);
       buf.extend_from_slice(&HEADER);
       buf.extend_from_slice(&frame.data);
       buf.extend_from_slice(&TAIL);

       Ok(buf.freeze())  // Zero-copy conversion to Bytes
   }
   ```

5. ADD PERFORMANCE MONITORING:
   ```rust
   pub struct PerformanceMonitor {
       histogram: hdrhistogram::Histogram<u64>,
       fps_counter: FpsCounter,
   }

   impl PerformanceMonitor {
       pub fn record_frame_time(&mut self, duration: Duration) {
           self.histogram.record(duration.as_micros() as u64).unwrap();
       }

       pub fn get_percentiles(&self) -> FrameTimeStats {
           FrameTimeStats {
               p50: self.histogram.value_at_percentile(50.0),
               p95: self.histogram.value_at_percentile(95.0),
               p99: self.histogram.value_at_percentile(99.0),
           }
       }
   }
   ```

MIGRATION STEPS:

1. PHASE 1 - ADD METRICS:
   - Implement StreamMetrics without changing functionality
   - Add performance counters to identify bottlenecks
   - Establish baseline measurements

2. PHASE 2 - BUFFER POOLING:
   - Implement FrameBufferPool
   - Gradually replace allocations with pool acquisitions
   - Monitor pool hit rates and adjust sizes

3. PHASE 3 - LOCK-FREE EXCHANGE:
   - Replace Mutex<Option<Vec<u8>>> with AtomicCell
   - Implement zero-copy frame updates
   - Reduce contention between producers and consumers

4. PHASE 4 - ADAPTIVE STREAMING:
   - Implement quality adjustment logic
   - Add frame dropping based on client lag
   - Dynamic FPS adjustment

5. PHASE 5 - MONITORING:
   - Add Prometheus metrics
   - Create dashboards for stream health
   - Set up alerts for degraded performance

BEST PRACTICES TO FOLLOW:
- Use RAII for buffer lifecycle management
- Prefer lock-free structures where possible
- Implement backpressure to prevent resource exhaustion
- Monitor everything that matters
- Use zero-copy operations with bytes crate
- Pre-allocate buffers based on expected sizes
- Implement graceful degradation
- Document performance characteristics

ANTI-PATTERNS TO AVOID:
- Don't allocate new buffers for each frame
- Don't hold locks while doing I/O
- Don't clone data unnecessarily
- Don't ignore backpressure
- Don't use unbounded channels
- Don't assume fixed frame rates
- Don't block async tasks

VALIDATION CRITERIA:
- Memory allocations reduced by >90%
- CPU usage reduced by >50%
- Support for 60fps streaming
- Frame latency <10ms p99
- Graceful handling of slow clients
- No memory leaks under load
- Metrics accessible via API

PERFORMANCE TARGETS:
- 1080p@60fps with <5% CPU per stream
- <1ms frame acquisition time
- <100MB memory usage for 10 concurrent streams
- Zero frame drops under normal load
- <10ms end-to-end latency

TESTING REQUIREMENTS:
- Benchmark tests for buffer pool
- Load tests with multiple concurrent clients
- Stress tests for memory leaks
- Latency distribution tests
- Network condition simulation
- Frame drop behavior validation
- Performance regression tests
